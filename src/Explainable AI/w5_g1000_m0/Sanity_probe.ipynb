{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717e87a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, random\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from copy import deepcopy\n",
    "from burst_utils import build_data_list, GCN, run_epoch, FEAT_NAMES\n",
    "\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "# assumes you have: build_data_list(window, gap, mask_shift) → List[Data]\n",
    "# and: run_epoch, GCN, FEAT_NAMES, clean_and_scale_data already defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e80f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/DATA/hdhanu/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 bursts (0 graphs) with NaNs\n",
      "Scaled data saved to .tmp_scaled.pt\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a single (w,g,m) configuration\n",
    "data_list = build_data_list(window=5, gap=1000, mask_shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e140885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64dccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with shuffled labels ≈ 0.493 (should be ~0.5)\n"
     ]
    }
   ],
   "source": [
    "# 2. Shuffle-label probe\n",
    "from torch_geometric.loader import DataLoader\n",
    "def shuffle_label_probe(data_list):\n",
    "    data_shuffled = deepcopy(data_list)\n",
    "    labels = [d.y.item() for d in data_shuffled]\n",
    "    random.shuffle(labels)\n",
    "    for d, y in zip(data_shuffled, labels):\n",
    "        d.y = torch.tensor([y])\n",
    "\n",
    "    # simple 80/20 split (no groups needed because leakage is what we test)\n",
    "    split = int(0.8*len(data_shuffled))\n",
    "    tr, te = data_shuffled[:split], data_shuffled[split:]\n",
    "\n",
    "    dl_k = dict(batch_size=32, pin_memory=True, num_workers=0, shuffle=True)\n",
    "    tr_ld, te_ld = DataLoader(tr, **dl_k), DataLoader(te, **dl_k | {\"shuffle\":False})\n",
    "\n",
    "    model = GCN(in_channels=len(FEAT_NAMES), hidden=64, num_classes=2)\n",
    "    model = model.to(device := torch.device('cpu'))\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    crit  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        run_epoch(model, tr_ld, crit, device, train=True, opt=opt)\n",
    "\n",
    "    _, acc, _, _, _ = run_epoch(model, te_ld, crit, device, compute_prf=False)\n",
    "    print(f\"Accuracy with shuffled labels ≈ {acc:.3f} (should be ~0.5)\")\n",
    "\n",
    "shuffle_label_probe(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853ea774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: F1 = 0.996\n",
      "Fold 2: F1 = 0.997\n",
      "Fold 3: F1 = 1.000\n",
      "Fold 4: F1 = 0.998\n",
      "Fold 5: F1 = 1.000\n",
      "\n",
      "Mean ± SD F1 across bursts: 0.998 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Leave-one-burst-out cross-validation\n",
    "def leave_one_burst_out(data_list, k=5):\n",
    "    groups = np.array([d.burst_id for d in data_list])\n",
    "    gkf    = GroupKFold(n_splits=k)\n",
    "    f1_scores = []\n",
    "\n",
    "    for fold, (tr_i, te_i) in enumerate(gkf.split(np.zeros(len(data_list)), groups=groups)):\n",
    "        tr = [data_list[i] for i in tr_i]\n",
    "        te = [data_list[i] for i in te_i]\n",
    "\n",
    "        dl_k = dict(batch_size=32, pin_memory=True, num_workers=0)\n",
    "        tr_ld = DataLoader(tr, shuffle=True, **dl_k)\n",
    "        te_ld = DataLoader(te, **dl_k)\n",
    "\n",
    "        model = GCN(len(FEAT_NAMES), 64, 2).to('cpu')\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        crit  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for _ in range(30):\n",
    "            run_epoch(model, tr_ld, crit, 'cpu', train=True, opt=opt)\n",
    "        _, _, prec, rec, f1 = run_epoch(model, te_ld, crit, 'cpu', compute_prf=True)\n",
    "        print(f\"Fold {fold+1}: F1 = {f1:.3f}\")\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    print(f\"\\nMean ± SD F1 across bursts: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n",
    "\n",
    "leave_one_burst_out(data_list, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2b1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch\n",
    "def shuffle_node_ids(graphs):\n",
    "    gs = []\n",
    "    for d in graphs:\n",
    "        idx = torch.randperm(d.x.size(0))\n",
    "        d2  = copy.deepcopy(d)\n",
    "        d2.x = d.x[idx]             # permute rows\n",
    "        # remap edge_index\n",
    "        mapping = {old.item(): new for new, old in enumerate(idx)}\n",
    "        d2.edge_index = d.edge_index.clone()\n",
    "        d2.edge_index[0] = d2.edge_index[0].apply_(lambda i: mapping[i])\n",
    "        d2.edge_index[1] = d2.edge_index[1].apply_(lambda i: mapping[i])\n",
    "        gs.append(d2)\n",
    "    return gs\n",
    "\n",
    "shuffled = shuffle_node_ids(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a49e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, copy\n",
    "means = np.vstack([d.x.numpy() for d in data_list]).mean(axis=0)\n",
    "\n",
    "def constant_features(graphs):\n",
    "    gs = []\n",
    "    for d in graphs:\n",
    "        d2 = copy.deepcopy(d)\n",
    "        d2.x[:] = torch.tensor(means, dtype=d2.x.dtype)\n",
    "        gs.append(d2)\n",
    "    return gs\n",
    "\n",
    "const_feats = constant_features(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ba13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID-shuffled    : acc = 0.813  F1 = 0.843\n",
      "Const-feature  : acc = 0.500  F1 = 0.667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "device = torch.device('cpu')  # or 'cuda' if you have a GPU\n",
    "def evaluate_variant(graphs, label):\n",
    "    split = int(0.8*len(graphs))\n",
    "    tr, te = graphs[:split], graphs[split:]\n",
    "    dl_k = dict(batch_size=32, shuffle=True)\n",
    "    tr_ld = DataLoader(tr, **dl_k)\n",
    "    te_ld = DataLoader(te, batch_size=32)\n",
    "\n",
    "    model = GCN(len(FEAT_NAMES), 64, 2).to(device)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    crit  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(30):\n",
    "        run_epoch(model, tr_ld, crit, device, train=True, opt=opt)\n",
    "\n",
    "    _, acc, _, _, f1 = run_epoch(model, te_ld, crit, device, compute_prf=True)\n",
    "    print(f\"{label:15s}: acc = {acc:.3f}  F1 = {f1:.3f}\")\n",
    "\n",
    "evaluate_variant(shuffled,   \"ID-shuffled\")\n",
    "evaluate_variant(const_feats, \"Const-feature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb650a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand-edges     : acc = 0.733  F1 = 0.788\n"
     ]
    }
   ],
   "source": [
    "def randomise_edges(graphs):\n",
    "    import copy, torch\n",
    "    gs = []\n",
    "    for d in graphs:\n",
    "        num_nodes = d.x.size(0)\n",
    "        num_edges = d.edge_index.size(1)\n",
    "        rand_src  = torch.randint(0, num_nodes, (num_edges,))\n",
    "        rand_dst  = torch.randint(0, num_nodes, (num_edges,))\n",
    "        d2 = copy.deepcopy(d)\n",
    "        d2.edge_index = torch.stack([rand_src, rand_dst], dim=0)\n",
    "        gs.append(d2)\n",
    "    return gs\n",
    "\n",
    "rand_edges = randomise_edges(data_list)\n",
    "for i in range(len(rand_edges)):\n",
    "    rand_edges[i].edge_index = torch.empty((2,0),dtype=torch.long)\n",
    "evaluate_variant(rand_edges, \"Rand-edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6cabf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand-edges (empty edges): acc = 0.537  F1 = 0.682\n"
     ]
    }
   ],
   "source": [
    "# Rand edges with empty edge_index\n",
    "def randomise_edges(graphs):\n",
    "    import copy, torch\n",
    "    gs = []\n",
    "    for d in graphs:\n",
    "        num_nodes = d.x.size(0)\n",
    "        num_edges = d.edge_index.size(1)\n",
    "        rand_src  = torch.randint(0, num_nodes, (num_edges,))\n",
    "        rand_dst  = torch.randint(0, num_nodes, (num_edges,))\n",
    "        d2 = copy.deepcopy(d)\n",
    "        d2.edge_index = torch.stack([rand_src, rand_dst], dim=0)\n",
    "        gs.append(d2)\n",
    "    return gs\n",
    "\n",
    "rand_edges = randomise_edges(data_list)\n",
    "for i in range(len(rand_edges)):\n",
    "    rand_edges[i].edge_index = torch.empty((2,0),dtype=torch.long)\n",
    "evaluate_variant(rand_edges, \"Rand-edges (empty edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Degree-preserving edge shuffle\n",
    "# ------------------------------------------------------------\n",
    "def degree_preserving_shuffle(d):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(d.x.size(0)))\n",
    "    G.add_edges_from(d.edge_index.t().tolist())\n",
    "\n",
    "    # Maslov–Sneppen edge swap — skip if graph too small\n",
    "    try:\n",
    "        nx.double_edge_swap(\n",
    "            G,\n",
    "            nswap=max(1, 2 * G.number_of_edges()),\n",
    "            max_tries=100 * G.number_of_edges(),\n",
    "            seed=random.randint(0, 1_000_000),\n",
    "        )\n",
    "    except nx.NetworkXError:\n",
    "        pass  # leave tiny graphs unchanged\n",
    "\n",
    "    d2 = copy.deepcopy(d)\n",
    "    edges = list(G.edges())\n",
    "    # make directed / undirected match original\n",
    "    if not d.is_directed():\n",
    "        edges = edges + [(v, u) for u, v in edges]\n",
    "    d2.edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    return d2\n",
    "\n",
    "\n",
    "rand_deg = [degree_preserving_shuffle(g) for g in data_list]\n",
    "evaluate_variant(rand_deg, \"Deg-preserved\")     # uses the earlier GNN evaluate_variant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c0a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure-feature MLP: acc = 0.607  F1 = 0.718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import copy, torch, networkx as nx, random\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.data import Batch\n",
    "from torch.utils.data import TensorDataset, DataLoader as DL\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Pure-feature MLP baseline\n",
    "#    → need a *different* loader & run loop\n",
    "# ------------------------------------------------------------\n",
    "class BaselineMLP(torch.nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_dim, 64), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),     torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def pooled_loader(graphs, shuffle):\n",
    "    \"\"\"Return a DataLoader whose batches are flat [num_feat] tensors.\"\"\"\n",
    "    X = torch.stack([g.x.mean(dim=0) for g in graphs])\n",
    "    y = torch.cat([g.y for g in graphs])\n",
    "    ds = TensorDataset(X, y)\n",
    "    return DL(ds, batch_size=32, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def evaluate_variant_mlp(graphs, label):\n",
    "    split = int(0.8 * len(graphs))\n",
    "    tr, te = graphs[:split], graphs[split:]\n",
    "\n",
    "    tr_ld = pooled_loader(tr, shuffle=True)\n",
    "    te_ld = pooled_loader(te, shuffle=False)\n",
    "\n",
    "    model = BaselineMLP(len(FEAT_NAMES)).to(device)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    crit  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # simple epoch loop\n",
    "    for _ in range(30):\n",
    "        model.train()\n",
    "        for X, y in tr_ld:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = crit(out, y)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "    # evaluation\n",
    "    model.eval(); corr, all_y, all_p = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in te_ld:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            out  = model(X)\n",
    "            pred = out.argmax(1)\n",
    "            corr += (pred == y).sum().item()\n",
    "            all_y.extend(y.cpu().numpy())\n",
    "            all_p.extend(pred.cpu().numpy())\n",
    "\n",
    "    acc = corr / len(te_ld.dataset)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(\n",
    "        all_y, all_p, average='binary', zero_division=0)\n",
    "    print(f\"{label:15s}: acc = {acc:.3f}  F1 = {f1:.3f}\")\n",
    "\n",
    "\n",
    "evaluate_variant_mlp(data_list, \"Pure-feature MLP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81dc17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
